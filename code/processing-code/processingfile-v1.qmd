---
title: "Data cleaning for Project"
author: "Prasanga Paudel"
date: "2024-02-17"
output: html_document
---

Please see the readme file before running the codes.


```{r}
#loading the necessary packages
library(here)
library(dplyr)
library(skimr)
library(ggplot2)
library(readxl)
library(tidyr)
library(writexl)
```





## Data import and cleaning
Here, we will import the original file downloaded from the website.

```{r}
file_path <- here("data","raw-data", "wdi-oecd.xlsx")
data <- read_excel(file_path, sheet="Data")
```



## Preliminary check of the original data 

_This is the snapshot of the data as of now._
```{r}
head(data)
```


## Data Cleaning

We will now change the name of the variables so that R can better understand the names and to avoid errors during the data analysis process.

```{r}
# Cleaning year columns: Removing brackets, text, and spaces
colnames(data) <- gsub("\\[.*\\]|\\s", "", colnames(data))  

# We will now check the corrected names
print(colnames(data))
```
Here, we can observe that the names have been assigned as required and we no longer have spaces and unwanted words and characters in the variable names.


## Data Transformation

As the necesary variables require to go further with analysis are present in rows under the column "SeriesName", we need to make sure that we have these variables as column names and not as rows. We will now perform the necessary transformations. We will also need to transform the year values from column names to rows as it would make more convinient to run a time series analysis. We will therefore create a new variable Year to save the values for different years. 

```{r}
# Reshaping the data from wide to long format
data_long <- data %>%
  pivot_longer(
    cols = starts_with("20"),  # Selecting all year columns (2010 to 2020)
    names_to = "Year",         # Naming the new column for years
    values_to = "Value"        # Naming the new column for values
  )

# Viewing the reshaped data
print(head(data_long))
```
As we can see the year data has been arranged as required. Now, we will transform the variables into column names. But, before doing that, we will remove all the special characters from the to-be variable names, and also replace spaces with unerscore.

```{r}
# Cleaning the Series_Name column
data_long <- data_long %>%
  mutate(
    SeriesName = gsub("[^a-zA-Z0-9 ]", "", SeriesName),  # Removing special characters
    SeriesName = gsub(" ", "_", SeriesName)               # Replacing spaces with _
  )

# View the updated Series_Name column
print(unique(data_long$SeriesName))
```
Now, the variables are ready to be transformed.

We will further insure that no replication has been produuced during out data analysis process.

```{r}
# Remove duplicates
data_long <- data_long %>%
  distinct(CountryName, CountryCode, SeriesCode, Year, SeriesName, .keep_all = TRUE)
```

Here, we will transform the variables as column names with appropriates values assigned to them correctly.

CAUTION: This chunck might take a long time to process. Please wait pariently for few minutes (2-5 minutes if your PC has 16gb RAM) until the code processes itself.


```{r}
# Spread the SeriesName into separate columns
data_final <- data_long %>%
  pivot_wider(
    names_from = SeriesName,  # Use SeriesName to create new columns
    values_from = Value       # Fill the new columns with the corresponding values
  )

```


## Checking if the transformation is accurate

In this section, we will verify if our transformation of the dataset was accurate.

```{r}
# Extract value from the original dataset
original_value <- data %>%
  filter(CountryName == "Hungary", SeriesName == "Primary education, teachers") %>%
  pull(`2010`)  # Replace `2010` with the correct column name for the year 2010

# Print the original value
print(original_value)
```
This provides the value for Primary education, teachers for Hungary based on original dataset.

CAUTION: This chunck might also consume a good amoung of your PC's memory, expect upto 1-2 minutes for the code to process.

```{r}
# Convert Year to numeric
data_final <- data_final %>%
  mutate(Year = as.numeric(Year))

# Extract the value
transformed_value <- data_final %>%
  filter(CountryName == "Hungary", Year == 2010) %>%
  pull(Primary_education_teachers)

# Remove missing values and print non-missing values
non_missing_values <- na.omit(transformed_value)
cat(non_missing_values, sep = "\n")
```
This provides the value for Primary education, teachers for Hungary based on transformed dataset. 
Since they are equal, we have verified that our transformation was accurate.

## Creating a more compact dataset 

As the dataset has 10 years information for each country and currently this structure has resulted in creation of 641,817 observations, we will try to make it more compact and less complex.


CAUTION: This chunk could also take upto 1-2 minutes to process.

```{r}
data_collapsed <- data_final %>%
  group_by(CountryName, CountryCode, Year) %>%
  summarize(across(everything(), ~ max(.x, na.rm = TRUE)), .groups = "drop")

```




## Saving the dataset for EDA

Now, we will save the dataset so that we will be able run EDA based on it.


```{r}
rds_path <- here("data", "processed-data", "processeddata.rds")
saveRDS(data_collapsed, rds_path)
```

Saving an excel file as well.

```{r}
xl_path <- here("data", "processed-data", "processeddata.xlsx")
writexl::write_xlsx(data_collapsed, xl_path)
```



